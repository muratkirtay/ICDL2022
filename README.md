# ICDL 2022
A repository for reproducing the results presented in ICDL 2022 submission.

> **Abstract:** Forming trust in interaction partners is a social ability that humans learn through development by utilizing multimodal sensorimotor information; yet, endowing a robot with this ability is poorly explored in social robotics. This study presents a robot trust model based on the cognitive load that uses multimodal information in a learning setting to assess the trustworthiness of heterogeneous interaction partners. As a test-bed, we design an interactive task where a humanoid robot is asked to perform a sequential multimodal (i.e., audio-visual) pattern recall task with the goal of minimizing its cognitive load by receiving help from its partners who may have one of the guiding strategies of reliable, unreliable, or random. To do this effectively, the robot must assess the trustworthiness of its partners. The robot is equipped with two cognitive modules: a multimodal auto-associative memory and an internal reward module. The former represents the multimodal cognitive processing of the robot that allows a 'cognitive load' or 'cost' to be assigned to the processing that takes place, while the latter converts the cognitive processing cost to an internal reward signal that drives the cognitive cost-based behavior learning. A small humanoid robot, Nao, is used as the actor in the interactive task, where it asks for help from an interaction partner when its action leads to a high cognitive load. Then the robot receives an action suggestion from the partner and follows it. After going through interactive experiments with each partner, the robot uses the cognitive load yielded during the interaction to assess the trustworthiness of the partners, namely it associates high trustworthiness with low cognitive load. At the end of the experiments, we provide a free choice to the Nao robot to select trustworthy interaction partners. Overall, the results show that the robot selects partners that are designated with reliable policies as trustworthy regardless of them being human or not.




## Folder and file descriptions
+ **Assets:** this folder contains various assets (e.g., memory patterns, noisy patterns) to run the experiment.
+ **Data:** this folder contains data collected during the experiments in .pkl format. Note that the figures in the paper and in **Figures** folder can be generated by using the .pkl files. 
+ **Figures:** this folder contains the figures in the paper and addtional figures for the data collected during the experiments.
+ **Scipts:** python scripts to generate the tables and figures can be found in the previous publication [ROMAN2022](https://github.com/muratkirtay/RoMAN2021) and [ADAPTIVE2019](https://github.com/muratkirtay/ADAPTIVE2019) repos were used.
+ **Experiment videos:** this folder contains the experiment videos. Due to their size, it can not uploaded to Github, yet you can access with this link: [https://box.hu-berlin.de/d/d18573e6c3e94b5a9b54/](https://box.hu-berlin.de/d/d18573e6c3e94b5a9b54/)
+ [Authors' copy of reference 4.](https://box.hu-berlin.de/f/e8200ff0cb7149dba7f7/) 
 
 




